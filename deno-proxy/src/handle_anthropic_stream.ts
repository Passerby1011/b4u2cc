import { ToolifyParser } from "./parser.ts";
import { ClaudeStream } from "./claude_writer.ts";
import { SSEWriter } from "./sse.ts";
import { ProxyConfig } from "./config.ts";
import { log } from "./logging.ts";
import { ToolCallDelimiter } from "./signals.ts";
import { ToolCallRetryHandler } from "./tool_retry.ts";

export async function handleAnthropicStream(
  response: Response,
  writer: SSEWriter,
  config: ProxyConfig,
  requestId: string,
  delimiter?: ToolCallDelimiter,
  thinkingEnabled = false,
  inputTokens = 0,
  model = "claude-3-5-sonnet-20241022",
  originalMessages: any[] = [],
  upstreamUrl = "",
  upstreamHeaders: Record<string, string> = {},
  protocol: "openai" | "anthropic" = "anthropic",
) {
  const parser = new ToolifyParser(delimiter, thinkingEnabled, requestId);
  const claudeStream = new ClaudeStream(writer, config, requestId, inputTokens, model);

  await claudeStream.init();

  const reader = response.body?.getReader();
  if (!reader) return;

  const decoder = new TextDecoder();
  let buffer = "";

  try {
    while (true) {
      let readResult;
      try {
        readResult = await reader.read();
      } catch (readError) {
        log("error", "Stream read error", {
          error: String(readError),
          requestId
        });
        // é€šçŸ¥å®¢æˆ·ç«¯å‘ç”Ÿäº†æµè¯»å–é”™è¯¯
        await writer.send({
          event: "error",
          data: {
            error: {
              type: "stream_error",
              message: "Failed to read from upstream: " + String(readError)
            }
          }
        }, true);
        break;
      }

      const { done, value } = readResult;
      if (done) break;

      buffer += decoder.decode(value, { stream: true });
      const lines = buffer.split("\n");
      buffer = lines.pop() || "";

      let eventType = "";

      for (const line of lines) {
        const trimmed = line.trim();
        if (!trimmed) continue;

        if (trimmed.startsWith("event: ")) {
          eventType = trimmed.slice(7);
        } else if (trimmed.startsWith("data: ")) {
          const jsonStr = trimmed.slice(6);
          try {
            const data = JSON.parse(jsonStr);

            // å¤„ç†ä¸åŒç±»å‹çš„ Anthropic äº‹ä»¶
            if (eventType === "content_block_delta") {
              const delta = data.delta;
              if (delta?.type === "text_delta") {
                const text = delta.text;
                if (text) {
                  for (const char of text) {
                    parser.feedChar(char);
                    await claudeStream.handleEvents(parser.consumeEvents());
                  }
                }
              }
            } else if (eventType === "message_start") {
              // å¯ä»¥åœ¨è¿™é‡Œæ›´æ–° input_tokensï¼Œå¦‚æœä¸Šæ¸¸è¿”å›äº†æ›´ç²¾ç¡®çš„å€¼
            } else if (eventType === "message_delta") {
              // å¤„ç†ç»“æŸçŠ¶æ€ç­‰
            }
          } catch (e) {
            log("error", "Failed to parse Anthropic SSE chunk", { error: String(e), jsonStr });
          }
        }
      }
    }

    parser.finish();
    const events = parser.consumeEvents();
    const failedEvent = events.find(e => e.type === "tool_call_failed");

    // ğŸ”‘ æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨å¤±è´¥ + é‡è¯•å·²å¯ç”¨
    if (failedEvent && 
        config.toolCallRetry?.enabled && 
        delimiter &&
        originalMessages.length > 0 &&
        upstreamUrl) {
      
      // ğŸ”‘ ä¿æŒè¿æ¥ï¼šå‘é€å¿ƒè·³
      if (config.toolCallRetry?.keepAlive !== false) {
        await writer.send({
          event: "ping",
          data: { type: "ping" }
        });
      }

      const maxRetries = config.toolCallRetry?.maxRetries || 1;
      let retrySuccess = false;

      // é‡è¯•å¾ªç¯
      for (let attempt = 1; attempt <= maxRetries; attempt++) {
        const retryHandler = new ToolCallRetryHandler(
          config,
          requestId,
          originalMessages,
          upstreamUrl,
          upstreamHeaders,
          protocol,
          model  // ğŸ”‘ ä¼ é€’åŸå§‹è¯·æ±‚çš„æ¨¡å‹
        );

        const retryResult = await retryHandler.retry(
          failedEvent.content,
          failedEvent.priorText || "",
          delimiter,
          attempt
        );

        if (retryResult.success) {
          // ğŸ”‘ é‡è¯•æˆåŠŸï¼šå‘é€å·¥å…·è°ƒç”¨äº‹ä»¶
          await claudeStream.handleEvents([{
            type: "tool_call",
            call: retryResult.result!
          }]);
          retrySuccess = true;
          break;
        } else if (attempt < maxRetries) {
          // ç»§ç»­ä¸‹ä¸€æ¬¡é‡è¯•
          log("info", "Retry attempt failed, will retry again", {
            requestId,
            attempt,
            maxRetries,
            error: retryResult.error
          });
          
          // ğŸ”‘ ä¿æŒè¿æ¥ï¼šå†æ¬¡å‘é€å¿ƒè·³
          if (config.toolCallRetry?.keepAlive !== false) {
            await writer.send({
              event: "ping",
              data: { type: "ping" }
            });
          }
        }
      }

      if (!retrySuccess) {
        // ğŸ”‘ æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼šé™çº§ä¸ºæ–‡æœ¬
        log("error", "All retry attempts exhausted, falling back to text", {
          requestId,
          totalAttempts: maxRetries
        });
        
        await claudeStream.handleEvents([{
          type: "text",
          content: failedEvent.content
        }]);
      }
    } else {
      // æ­£å¸¸å¤„ç†äº‹ä»¶
      await claudeStream.handleEvents(events);
    }
  } catch (e) {
    log("error", "Error in Anthropic stream handling", { error: String(e), requestId });
    // å°è¯•é€šçŸ¥å®¢æˆ·ç«¯å‘ç”Ÿäº†é”™è¯¯
    try {
      await writer.send({
        event: "error",
        data: {
          error: {
            type: "stream_error",
            message: String(e)
          }
        }
      }, true);
    } catch {
      // å¿½ç•¥å‘é€é”™è¯¯æ—¶çš„å¼‚å¸¸
    }
  } finally {
    reader.releaseLock();
  }
  
  return { outputTokens: claudeStream.getTotalOutputTokens() };
}
